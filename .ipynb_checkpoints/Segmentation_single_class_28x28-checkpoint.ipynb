{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All RBF Layers in one Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gzip\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "from sklearn.gaussian_process.kernels import PairwiseKernel\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop, Adam, Nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "# read data set\n",
    "f = gzip.open('./data/train-images-idx3-ubyte.gz', 'rb')\n",
    "x_train = np.array(np.frombuffer(f.read(), np.uint8, offset=16))\n",
    "\n",
    "f = gzip.open('./data/train-labels-idx1-ubyte.gz', 'rb')\n",
    "y_train = np.array(np.frombuffer(f.read(), np.uint8, offset=8))\n",
    "\n",
    "f = gzip.open('./data/t10k-images-idx3-ubyte.gz', 'rb')\n",
    "x_test = np.array(np.frombuffer(f.read(), np.uint8, offset=16))\n",
    "\n",
    "f = gzip.open('./data/t10k-labels-idx1-ubyte.gz', 'rb')\n",
    "y_test = np.array(np.frombuffer(f.read(), np.uint8, offset=8))\n",
    "\n",
    "# data preprocessing\n",
    "x_train = np.reshape(x_train, (-1, 784))\n",
    "x_train = x_train / 255\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_test = np.reshape(x_test, (-1, 784))\n",
    "x_test = x_test / 255\n",
    "x_test = x_test.astype(np.float32)\n",
    "\n",
    "# get each training images\n",
    "idx_train = [0 for i in range(10)]\n",
    "idx_test = [0 for i in range(10)]\n",
    "for i in range(10):\n",
    "    idx_train[i] = (y_train == i)\n",
    "    idx_test[i] = (y_test == i)\n",
    "      \n",
    "x_train_38 = x_train[idx_train[3]+idx_train[8]]\n",
    "x_test_38 = x_test[idx_test[3]+idx_test[8]]\n",
    "\n",
    "# x_temptr_38 = x_train[idx_train[3]+idx_train[8]][0:10000]\n",
    "# x_tempte_38 = x_test[idx_test[3]+idx_test[8]][0:1500]\n",
    "\n",
    "# y_train_38 = y_train[idx_train[3]+idx_train[8]][0:1000]\n",
    "# print(np.count_nonzero(y_train_38[y_train_38==3]))\n",
    "\n",
    "# one-hot encoding\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "y_train_38 = y_train[idx_train[3]+idx_train[8]]\n",
    "y_test_38 = y_test[idx_test[3]+idx_test[8]]\n",
    "\n",
    "# y_temptr_38 = y_train[idx_train[3]+idx_train[8]][0:10000]\n",
    "# y_tempte_38 = y_test[idx_test[3]+idx_test[8]][0:1500]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means clustering to find centers\n",
    "_38 = []\n",
    "for i in [3,8]:\n",
    "    kmeans_model = KMeans(10)\n",
    "    kmeans_model.fit(x_train[idx_train[i]])\n",
    "    _38.extend(kmeans_model.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot cluster centers as images\n",
    "fig = plt.figure(figsize = (10,10))\n",
    "\n",
    "for i in range(20):\n",
    "  subplot = fig.add_subplot(10, 10, i+1)\n",
    "  subplot.set_xticks([])\n",
    "  subplot.set_yticks([])\n",
    "  subplot.imshow(np.reshape(_38[i]*255, (28, 28)), cmap='gray')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seg_num = 50\n",
    "\n",
    "# center_7x7 =[]\n",
    "# row_7x7 = [random.randrange(0,29-7) for _ in range(seg_num)]\n",
    "# col_7x7 = [random.randrange(0,29-7) for _ in range(seg_num)]\n",
    "\n",
    "# for i in range(seg_num):\n",
    "#     for center in _38:\n",
    "#         center_7x7.extend(center[r*28+col_7x7[i] : r*28+(col_7x7[i]+7)] \n",
    "#                                 for r in range(row_7x7[i],row_7x7[i]+7))\n",
    "\n",
    "# center_7x7 = np.reshape(center_7x7,(-1,7*7))\n",
    "# print(center_7x7.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_num = 20\n",
    "center_14x14 =[]\n",
    "row_14x14 = [random.randrange(0,29-2) for _ in range(seg_num)]\n",
    "col_14x14 = [random.randrange(0,29-2) for _ in range(seg_num)]\n",
    "\n",
    "for i in range(seg_num):\n",
    "    for center in _38:\n",
    "        center_14x14.extend(center[r*28+col_14x14[i] : r*28+(col_14x14[i]+2)] \n",
    "                                for r in range(row_14x14[i],row_14x14[i]+2))\n",
    "\n",
    "center_14x14 = np.reshape(center_14x14,(-1,2*2))\n",
    "print(center_14x14.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# center_28x28 = _38[:]\n",
    "# center_28x28 = np.array(center_28x28)\n",
    "# print(center_28x28.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_7 = np.zeros((20,20))\n",
    "# for i in range(20):\n",
    "#     x_7[i][i] = 1\n",
    "\n",
    "x_14 = np.zeros((20,20))\n",
    "for i in range(20):\n",
    "    x_14[i][i] = 1\n",
    "\n",
    "# x_28 = np.zeros((20,20))\n",
    "# for i in range(20):\n",
    "#     x_28[i][i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trimg_7x7 = []\n",
    "# trlab_7x7 = []\n",
    "# testimg_7x7 = []\n",
    "# testlab_7x7 = []\n",
    "\n",
    "# for i in range(seg_num):\n",
    "    \n",
    "#     for arr in x_train_38:\n",
    "#         trimg_7x7.extend(arr[r*28+col_7x7[i] : r*28+(col_7x7[i]+7)]\n",
    "#                          for r in range(row_7x7[i],row_7x7[i]+7))\n",
    "        \n",
    "#     for arr in x_test_38:\n",
    "#         testimg_7x7.extend(arr[r*28+col_7x7[i] : r*28+(col_7x7[i]+7) ] \n",
    "#                                   for r in range(row_7x7[i],row_7x7[i]+7))   \n",
    "    \n",
    "#     for arr in y_train_38:    \n",
    "#         trlab_7x7.extend(arr)\n",
    "\n",
    "#     for arr in y_test_38:    \n",
    "#         testlab_7x7.extend(arr)\n",
    "\n",
    "# trimg_7x7 = np.reshape(trimg_7x7,(-1,7*7))  \n",
    "# testimg_7x7 = np.reshape(testimg_7x7,(-1,7*7))    \n",
    "# trlab_7x7 = np.reshape(trlab_7x7,(-1,10))\n",
    "# testlab_7x7 = np.reshape(testlab_7x7,(-1,10))\n",
    "\n",
    "# print(trimg_7x7.shape)\n",
    "# print(testimg_7x7.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimg_14x14 = []\n",
    "trlab_14x14 = []\n",
    "testimg_14x14 = []\n",
    "testlab_14x14 = []\n",
    "\n",
    "for i in range(seg_num):\n",
    "    for arr in x_train_38:\n",
    "        trimg_14x14.extend(arr[r*28+col_14x14[i] : r*28+(col_14x14[i]+2) ] \n",
    "                                  for r in range(row_14x14[i],row_14x14[i]+2))\n",
    "    for arr in x_test_38:\n",
    "        testimg_14x14.extend(arr[r*28+col_14x14[i] : r*28+(col_14x14[i]+2) ] \n",
    "                                  for r in range(row_14x14[i],row_14x14[i]+2))\n",
    "    \n",
    "    for arr in y_train_38:    \n",
    "        trlab_14x14.extend(arr)\n",
    "\n",
    "    for arr in y_test_38:    \n",
    "        testlab_14x14.extend(arr)\n",
    "\n",
    "trimg_14x14 = np.reshape(trimg_14x14,(-1,2*2))  \n",
    "testimg_14x14 = np.reshape(testimg_14x14,(-1,2*2))    \n",
    "trlab_14x14 = np.reshape(trlab_14x14,(-1,10))\n",
    "testlab_14x14 = np.reshape(testlab_14x14,(-1,10))\n",
    "\n",
    "print(trimg_14x14.shape)\n",
    "print(testimg_14x14.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trimg_28x28 = []\n",
    "# trlab_28x28 = []\n",
    "# testimg_28x28 = []\n",
    "# testlab_28x28 = []\n",
    "\n",
    "# for i in range(10):\n",
    "#     for arr in x_train_38:\n",
    "#         trimg_28x28.extend(arr)\n",
    "#     for arr in x_test_38:\n",
    "#         testimg_28x28.extend(arr)\n",
    "#     for arr in y_train_38:    \n",
    "#         trlab_28x28.extend(arr)\n",
    "#     for arr in y_test_38:    \n",
    "#         testlab_28x28.extend(arr)\n",
    "\n",
    "# trimg_28x28 = np.reshape(trimg_28x28,(-1,28*28))  \n",
    "# testimg_28x28 = np.reshape(testimg_28x28,(-1,28*28))    \n",
    "# trlab_28x28 = np.reshape(trlab_28x28,(-1,10))\n",
    "# testlab_28x28 = np.reshape(testlab_28x28,(-1,10))\n",
    "\n",
    "# print(trimg_28x28.shape)\n",
    "# print(testimg_28x28.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = []\n",
    "temp2=[]\n",
    "temp3=[]\n",
    "temp4=[]\n",
    "\n",
    "kernel = PairwiseKernel(metric='polynomial') \n",
    "rbf_models = GaussianProcessRegressor(kernel=kernel,alpha=0.1).fit(center_14x14[0:20], x_14)\n",
    "\n",
    "temp1= (rbf_models.predict(trimg_14x14[0:len(x_train_38)]))\n",
    "temp2= (rbf_models.predict(testimg_14x14[0:len(x_test_38)]))\n",
    "print(temp1.shape)\n",
    "\n",
    "for i in range(1,seg_num):\n",
    "    rbf_models = GaussianProcessRegressor(kernel=kernel,alpha=0.1).fit(center_14x14[20*i:20*(i+1)], x_14)\n",
    "\n",
    "    temp1= np.hstack([temp1,(rbf_models.predict(trimg_14x14[len(x_train_38)*i:len(x_train_38)*(i+1)]))])\n",
    "    temp2= np.hstack([temp2,(rbf_models.predict(testimg_14x14[len(x_test_38)*i:len(x_test_38)*(i+1)]))])\n",
    "\n",
    "\n",
    "# rbf_models = GaussianProcessRegressor(kernel=kernel,alpha=0.1).fit(center_14x14, x_14)\n",
    "\n",
    "# temp3=(rbf_models.predict(trimg_14x14))\n",
    "# temp4=(rbf_models.predict(testimg_14x14))\n",
    "\n",
    "# rbf_models = GaussianProcessRegressor(kernel=kernel,alpha=0.1).fit(center_28x28, x_28)\n",
    "\n",
    "# temp5=(rbf_models.predict(trimg_28x28))\n",
    "# temp6=(rbf_models.predict(testimg_28x28))\n",
    "\n",
    "\n",
    "# temp1 = np.hstack([temp1,temp3])\n",
    "# temp1 = np.hstack([temp1,temp5])\n",
    "\n",
    "# temp2 = np.hstack([temp2,temp4])\n",
    "# temp2 = np.hstack([temp2,temp6])\n",
    "\n",
    "print(temp1.shape)\n",
    "print(temp2.shape)\n",
    "\n",
    "# trlab_7x7 = np.vstack([trlab_7x7,trlab_14x14])\n",
    "# print(trlab_7x7.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                4010      \n",
      "=================================================================\n",
      "Total params: 4,010\n",
      "Trainable params: 4,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "11982/11982 [==============================] - 2s 138us/step - loss: 1.8086 - acc: 0.4620\n",
      "Epoch 2/100\n",
      "11982/11982 [==============================] - 0s 14us/step - loss: 0.8987 - acc: 0.9024\n",
      "Epoch 3/100\n",
      "11982/11982 [==============================] - 0s 16us/step - loss: 0.5740 - acc: 0.9508\n",
      "Epoch 4/100\n",
      "11982/11982 [==============================] - 0s 14us/step - loss: 0.4279 - acc: 0.9590\n",
      "Epoch 5/100\n",
      "11982/11982 [==============================] - 0s 16us/step - loss: 0.3462 - acc: 0.9627\n",
      "Epoch 6/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.2942 - acc: 0.9648\n",
      "Epoch 7/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.2582 - acc: 0.9669\n",
      "Epoch 8/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.2318 - acc: 0.9685\n",
      "Epoch 9/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.2117 - acc: 0.9703\n",
      "Epoch 10/100\n",
      "11982/11982 [==============================] - 0s 14us/step - loss: 0.1958 - acc: 0.9705\n",
      "Epoch 11/100\n",
      "11982/11982 [==============================] - 0s 16us/step - loss: 0.1828 - acc: 0.9720\n",
      "Epoch 12/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.1722 - acc: 0.9726\n",
      "Epoch 13/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.1632 - acc: 0.9729\n",
      "Epoch 14/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.1557 - acc: 0.9737\n",
      "Epoch 15/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.1491 - acc: 0.9740\n",
      "Epoch 16/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.1433 - acc: 0.9743\n",
      "Epoch 17/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.1382 - acc: 0.9750\n",
      "Epoch 18/100\n",
      "11982/11982 [==============================] - 0s 16us/step - loss: 0.1337 - acc: 0.9749\n",
      "Epoch 19/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.1297 - acc: 0.9752\n",
      "Epoch 20/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.1260 - acc: 0.9756\n",
      "Epoch 21/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.1227 - acc: 0.9755\n",
      "Epoch 22/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.1198 - acc: 0.9760\n",
      "Epoch 23/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.1170 - acc: 0.9764\n",
      "Epoch 24/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.1146 - acc: 0.9767\n",
      "Epoch 25/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.1123 - acc: 0.9762\n",
      "Epoch 26/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.1102 - acc: 0.9767\n",
      "Epoch 27/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.1082 - acc: 0.9771\n",
      "Epoch 28/100\n",
      "11982/11982 [==============================] - 0s 14us/step - loss: 0.1064 - acc: 0.9770\n",
      "Epoch 29/100\n",
      "11982/11982 [==============================] - 0s 16us/step - loss: 0.1047 - acc: 0.9770\n",
      "Epoch 30/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.1030 - acc: 0.9781\n",
      "Epoch 31/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.1015 - acc: 0.9775\n",
      "Epoch 32/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.1001 - acc: 0.9776\n",
      "Epoch 33/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0987 - acc: 0.9780\n",
      "Epoch 34/100\n",
      "11982/11982 [==============================] - 0s 14us/step - loss: 0.0973 - acc: 0.9781\n",
      "Epoch 35/100\n",
      "11982/11982 [==============================] - 0s 16us/step - loss: 0.0962 - acc: 0.9784\n",
      "Epoch 36/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0950 - acc: 0.9783\n",
      "Epoch 37/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0938 - acc: 0.9781\n",
      "Epoch 38/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0929 - acc: 0.9789\n",
      "Epoch 39/100\n",
      "11982/11982 [==============================] - 0s 14us/step - loss: 0.0919 - acc: 0.9787\n",
      "Epoch 40/100\n",
      "11982/11982 [==============================] - 0s 16us/step - loss: 0.0910 - acc: 0.9789\n",
      "Epoch 41/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0900 - acc: 0.9791\n",
      "Epoch 42/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0891 - acc: 0.9789\n",
      "Epoch 43/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0883 - acc: 0.9788\n",
      "Epoch 44/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0875 - acc: 0.9791\n",
      "Epoch 45/100\n",
      "11982/11982 [==============================] - 0s 14us/step - loss: 0.0868 - acc: 0.9791\n",
      "Epoch 46/100\n",
      "11982/11982 [==============================] - 0s 18us/step - loss: 0.0861 - acc: 0.9789\n",
      "Epoch 47/100\n",
      "11982/11982 [==============================] - 0s 16us/step - loss: 0.0855 - acc: 0.9795\n",
      "Epoch 48/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0849 - acc: 0.9794\n",
      "Epoch 49/100\n",
      "11982/11982 [==============================] - 0s 14us/step - loss: 0.0841 - acc: 0.9797\n",
      "Epoch 50/100\n",
      "11982/11982 [==============================] - 0s 16us/step - loss: 0.0835 - acc: 0.9791\n",
      "Epoch 51/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0829 - acc: 0.9796\n",
      "Epoch 52/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0824 - acc: 0.9797\n",
      "Epoch 53/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0818 - acc: 0.9796\n",
      "Epoch 54/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0813 - acc: 0.9800\n",
      "Epoch 55/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0808 - acc: 0.9796\n",
      "Epoch 56/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0802 - acc: 0.9800\n",
      "Epoch 57/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0798 - acc: 0.9801\n",
      "Epoch 58/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0794 - acc: 0.9801\n",
      "Epoch 59/100\n",
      "11982/11982 [==============================] - 0s 14us/step - loss: 0.0790 - acc: 0.9798\n",
      "Epoch 60/100\n",
      "11982/11982 [==============================] - 0s 16us/step - loss: 0.0785 - acc: 0.9806\n",
      "Epoch 61/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0782 - acc: 0.9802\n",
      "Epoch 62/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0778 - acc: 0.9808\n",
      "Epoch 63/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0773 - acc: 0.9807\n",
      "Epoch 64/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0769 - acc: 0.9807\n",
      "Epoch 65/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0765 - acc: 0.9806\n",
      "Epoch 66/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0762 - acc: 0.9806\n",
      "Epoch 67/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0760 - acc: 0.9807\n",
      "Epoch 68/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0756 - acc: 0.9808\n",
      "Epoch 69/100\n",
      "11982/11982 [==============================] - 0s 14us/step - loss: 0.0752 - acc: 0.9811\n",
      "Epoch 70/100\n",
      "11982/11982 [==============================] - 0s 16us/step - loss: 0.0751 - acc: 0.9814\n",
      "Epoch 71/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0747 - acc: 0.9812\n",
      "Epoch 72/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0744 - acc: 0.9812\n",
      "Epoch 73/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0741 - acc: 0.9813\n",
      "Epoch 74/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0739 - acc: 0.9810\n",
      "Epoch 75/100\n",
      "11982/11982 [==============================] - 0s 14us/step - loss: 0.0735 - acc: 0.9809\n",
      "Epoch 76/100\n",
      "11982/11982 [==============================] - 0s 16us/step - loss: 0.0734 - acc: 0.9815\n",
      "Epoch 77/100\n",
      "11982/11982 [==============================] - 0s 14us/step - loss: 0.0730 - acc: 0.9814\n",
      "Epoch 78/100\n",
      "11982/11982 [==============================] - 0s 16us/step - loss: 0.0727 - acc: 0.9815\n",
      "Epoch 79/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0725 - acc: 0.9815\n",
      "Epoch 80/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0723 - acc: 0.9817\n",
      "Epoch 81/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0720 - acc: 0.9816\n",
      "Epoch 82/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0718 - acc: 0.9820\n",
      "Epoch 83/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0716 - acc: 0.9822\n",
      "Epoch 84/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0715 - acc: 0.9818\n",
      "Epoch 85/100\n",
      "11982/11982 [==============================] - 0s 14us/step - loss: 0.0711 - acc: 0.9817\n",
      "Epoch 86/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0710 - acc: 0.9821\n",
      "Epoch 87/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0708 - acc: 0.9819\n",
      "Epoch 88/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0706 - acc: 0.9818\n",
      "Epoch 89/100\n",
      "11982/11982 [==============================] - 0s 14us/step - loss: 0.0704 - acc: 0.9816\n",
      "Epoch 90/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0702 - acc: 0.9818\n",
      "Epoch 91/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0700 - acc: 0.9822\n",
      "Epoch 92/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0697 - acc: 0.9820\n",
      "Epoch 93/100\n",
      "11982/11982 [==============================] - 0s 14us/step - loss: 0.0696 - acc: 0.9819\n",
      "Epoch 94/100\n",
      "11982/11982 [==============================] - 0s 16us/step - loss: 0.0695 - acc: 0.9822\n",
      "Epoch 95/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0694 - acc: 0.9824\n",
      "Epoch 96/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0691 - acc: 0.9822\n",
      "Epoch 97/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0690 - acc: 0.9817\n",
      "Epoch 98/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0689 - acc: 0.9821\n",
      "Epoch 99/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0686 - acc: 0.9822\n",
      "Epoch 100/100\n",
      "11982/11982 [==============================] - 0s 15us/step - loss: 0.0686 - acc: 0.9821\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10, activation='softmax', input_shape=(400,)))\n",
    "\n",
    "\n",
    "model.summary()\n",
    "nadam=keras.optimizers.Nadam(lr=0.0005)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=nadam,metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(temp1,y_train_38\n",
    "                         ,batch_size=batch_size\n",
    "                         ,epochs=epochs\n",
    "                         ,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(temp2,y_test_38, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
